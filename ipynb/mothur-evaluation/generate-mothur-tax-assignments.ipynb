{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook relies on ``mothur`` being in the user's ``$PATH``. The QIIME 1.9.1 AWS has version 1.25.0 of mothur installed by default. To test with version 1.35.1 (the most recent at the time of this analysis) I installed that in my instance, and added it to my ``$PATH`` by adding the following line at the end of ``$HOME/.bashrc``:\n",
    "\n",
    "```\n",
    "export PATH=/home/ubuntu/data/mothur-1.35.1/source/:$PATH\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/mothur-1.35.1/source//mothur\r\n"
     ]
    }
   ],
   "source": [
    "!which mothur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os.path import join, exists, split, expandvars, sep\n",
    "from os import makedirs\n",
    "from tempfile import mkstemp\n",
    "from glob import glob\n",
    "from itertools import product\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project_dir = expandvars(\"$HOME/data/short-read-tax-assignment\")\n",
    "data_dir = join(project_dir, \"data\")\n",
    "\n",
    "reference_database_dir = expandvars(\"$HOME/data/\")\n",
    "results_dir = expandvars(\"$HOME/data/2015.06.24-tax-parameter-sweep-simulated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data set sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.parallel import Client\n",
    "rc = Client()\n",
    "lview = rc.load_balanced_view()\n",
    "\n",
    "@lview.parallel()\n",
    "def call_cmd(cmd):\n",
    "    from qcli import qcli_system_call\n",
    "    stdout, stderr, retval = qcli_system_call(cmd)\n",
    "    # return stdout, stderr, the return value, and the command\n",
    "    # the command is useful in case it needs to be re-run\n",
    "    return stdout, stderr, retval, cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we're going to define the data sets that we'll sweep over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_iterations = 5\n",
    "dataset_reference_combinations = []\n",
    "for iteration in range(num_iterations):\n",
    "    dataset_reference_combinations.append(('B1-iter%d' % iteration, 'gg_13_8_otus'))\n",
    "    dataset_reference_combinations.append(('B2-iter%d' % iteration, 'gg_13_8_otus'))\n",
    "    dataset_reference_combinations.append(('F1-iter%d' % iteration, 'unite-97-rep-set'))\n",
    "    dataset_reference_combinations.append(('F2-iter%d' % iteration, 'unite-97-rep-set'))\n",
    "\n",
    "reference_dbs = {'gg_13_8_otus' : (join(reference_database_dir, 'gg_13_8_otus/rep_set/97_otus.fasta'), \n",
    "                                   join(reference_database_dir, 'gg_13_8_otus/taxonomy/97_otu_taxonomy.txt')),\n",
    "                 'unite-97-rep-set' : (join(reference_database_dir, 'unite-14.11/97_otus.fasta'), \n",
    "                                       join(reference_database_dir, 'unite-14.11/97_otu_taxonomy.txt'))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncompress simulated reference database files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commands = []\n",
    "for e in dataset_reference_combinations:\n",
    "    zipped_refseqs_fp = join(data_dir, 'simulated-community', e[0], 'ref.fna.gz')\n",
    "    unzipped_refseqs_fp = join(data_dir, 'simulated-community', e[0], 'ref.fna')\n",
    "    cmd = \"gunzip -c %s > %s\" % (zipped_refseqs_fp, unzipped_refseqs_fp)\n",
    "    commands.append(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = call_cmd.map(commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the method/parameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "method_parameters_combinations = { # probabalistic classifiers\n",
    "              'mothur': {'confidence': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analyses = ['simulated-community']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commands = []\n",
    "command_template = \"mkdir -p %s ; assign_taxonomy.py -i %s -o %s -r %s -t %s -m %s %s\"\n",
    "for analysis in analyses:\n",
    "    analysis_input_dir = join(data_dir, analysis)\n",
    "    analysis_output_dir = join(results_dir, analysis)\n",
    "    for dataset, reference in dataset_reference_combinations:\n",
    "        dataset_input_dir = join(analysis_input_dir, dataset)\n",
    "        dataset_input_seqs = join(dataset_input_dir, 'rep_set.fna')\n",
    "        dataset_input_table = join(dataset_input_dir, 'table.biom')\n",
    "        unzipped_reference_seqs = join(dataset_input_dir, 'ref.fna')\n",
    "        full_reference_seqs = reference_dbs[reference][0]\n",
    "        reference_tax = reference_dbs[reference][1]\n",
    "        dataset_output_dir = join(analysis_output_dir, dataset, reference)\n",
    "        for method, parameters in method_parameters_combinations.items():\n",
    "            method_output_dir = join(dataset_output_dir, method)\n",
    "            parameter_ids = parameters.keys()\n",
    "            parameter_ids.sort()\n",
    "            for parameter_combination in product(*[parameters[id_] for id_ in parameter_ids]):\n",
    "                parameter_comb_id = ':'.join(map(str,parameter_combination))\n",
    "                parameter_output_dir = join(method_output_dir, ''.join([parameter_comb_id, ':partial-ref']))\n",
    "                parameter_str = ' '.join(['--%s %s' % e for e in zip(parameter_ids, parameter_combination)])\n",
    "                command = command_template % (parameter_output_dir,\n",
    "                                              dataset_input_seqs, parameter_output_dir, unzipped_reference_seqs, \n",
    "                                              reference_tax, method, parameter_str)\n",
    "                if not exists(parameter_output_dir): commands.append(command)\n",
    "                full_output_dir = join(method_output_dir, ''.join([parameter_comb_id, ':full-ref']))\n",
    "                command = command_template % (full_output_dir,\n",
    "                                              dataset_input_seqs, full_output_dir, full_reference_seqs, \n",
    "                                              reference_tax, method, parameter_str)\n",
    "                if not exists(full_output_dir): commands.append(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-89aca1823ec4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommands\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mcommands\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "shuffle(commands)\n",
    "print commands[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = call_cmd.map(commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate per-method biom tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simulated_community_data_dir = join(project_dir, 'data', 'simulated-community')\n",
    "biom_output_fps = []\n",
    "\n",
    "glob_str = join(results_dir, 'simulated-community', '*', '*', '*', '*', 'rep_set_tax_assignments.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commands = []\n",
    "\n",
    "taxonomy_map_fps = glob(glob_str)\n",
    "for taxonomy_map_fp in taxonomy_map_fps:\n",
    "    dataset_id = taxonomy_map_fp.split(sep)[-5]\n",
    "    biom_input_fp = join(simulated_community_data_dir, dataset_id, 'table-no-tax.biom')\n",
    "    output_dir = split(taxonomy_map_fp)[0]\n",
    "    biom_output_fp = join(output_dir,'table.biom')\n",
    "    if exists(biom_output_fp):\n",
    "        print \"Output file already exists: %s\" % biom_output_fp\n",
    "    cmd = \"biom add-metadata -i %s -o %s --observation-metadata-fp %s --observation-header otuid,taxonomy --sc-separated taxonomy --output-as-json\" % (biom_input_fp, biom_output_fp, taxonomy_map_fp)\n",
    "    commands.append(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n",
      "biom add-metadata -i /home/ubuntu/data/short-read-tax-assignment/data/simulated-community/F1-iter2/table-no-tax.biom -o /home/ubuntu/data/2015.06.24-tax-parameter-sweep-simulated/simulated-community/F1-iter2/unite-97-rep-set/mothur/0.0:partial-ref/table.biom --observation-metadata-fp /home/ubuntu/data/2015.06.24-tax-parameter-sweep-simulated/simulated-community/F1-iter2/unite-97-rep-set/mothur/0.0:partial-ref/rep_set_tax_assignments.txt --observation-header otuid,taxonomy --sc-separated taxonomy --output-as-json\n"
     ]
    }
   ],
   "source": [
    "print len(commands)\n",
    "print commands[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = call_cmd.map(commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove uncompressed reference databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commands = []\n",
    "for e in dataset_reference_combinations:\n",
    "    unzipped_refseqs_fp = join(data_dir, 'simulated-community', e[0], 'ref.fna')\n",
    "    cmd = \"rm %s\" % unzipped_refseqs_fp\n",
    "    commands.append(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "rm /home/ubuntu/data/short-read-tax-assignment/data/simulated-community/B1-iter0/ref.fna\n"
     ]
    }
   ],
   "source": [
    "print len(commands)\n",
    "print commands[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = call_cmd.map(commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move result files into repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a good idea to back up your ``results_dir`` prior to running this step (e.g., by creating a ``tgz`` of it). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "precomputed_results_dir = join(project_dir, \"data\", \"precomputed-results\", \"simulated-community\")\n",
    "method_dirs = glob(join(results_dir, '*', '*', '*', '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commands = []\n",
    "for method_dir in method_dirs:\n",
    "    fields = method_dir.split(sep)\n",
    "    dataset_id, database_id, method_id  = fields[-3], fields[-2], fields[-1] \n",
    "\n",
    "    new_location = join(precomputed_results_dir, dataset_id, database_id)\n",
    "    if exists(join(new_location, method_id)):\n",
    "        rmtree(join(new_location, method_id))\n",
    "    cmd = \"mv -f %s %s\" % (method_dir, new_location)\n",
    "    commands.append(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "mv -f /home/ubuntu/data/2015.02.25-tax-parameter-sweep-simulated/simulated-community/F1-iter2/unite-97-rep-set/sortmerna /home/ubuntu/data/short-read-tax-assignment/data/precomputed-results/simulated-community/F1-iter2/unite-97-rep-set\n"
     ]
    }
   ],
   "source": [
    "print len(commands)\n",
    "print commands[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = call_cmd.map(commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove directories for any failed runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2720 1\n"
     ]
    }
   ],
   "source": [
    "from os.path import getsize\n",
    "dirs = glob(expandvars(\"$HOME/data/2015.02.25-tax-parameter-sweep-simulated/simulated-community/*/*/*/*/\"))\n",
    "bad_dirs = []\n",
    "for d in dirs:\n",
    "    fp = join(d,'rep_set_tax_assignments.txt')\n",
    "    if not exists(fp) or getsize(fp) < 38:\n",
    "        bad_dirs.append(d)\n",
    "print len(dirs), len(bad_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/ubuntu/data/2015.02.25-tax-parameter-sweep-simulated/simulated-community/B1-iter1/gg_13_8_otus/sortmerna/0.76:0.9:5:0.8:1.0:partial-ref/']\n"
     ]
    }
   ],
   "source": [
    "print bad_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for e in bad_dirs:\n",
    "    !rm -r $e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
