{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the environment\n",
    "-----------------------\n",
    "\n",
    "First we'll import various functions that we'll need for generating the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from os import environ\n",
    "from os.path import join, exists, expandvars\n",
    "import pandas as pd\n",
    "from skbio.draw import boxplots\n",
    "\n",
    "from taxcompare.eval_framework import (get_expected_tables_lookup, \n",
    "                                       find_and_process_result_tables,\n",
    "                                       compute_mock_results,\n",
    "                                       compute_mantel,\n",
    "                                       generate_pr_scatter_plots,\n",
    "                                       boxplot_from_data_frame,\n",
    "                                       heatmap_from_data_frame,\n",
    "                                       method_by_dataset_a1,\n",
    "                                       method_by_dataset_a2,\n",
    "                                       performance_rank_comparisons,\n",
    "                                       parameter_comparisons,\n",
    "                                       method_by_dataset_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure local environment-specific values\n",
    "-------------------------------------------\n",
    "\n",
    "**This is the only cell that you will need to edit to generate reports locally.** After editing this cell, you can run all cells in this notebook to generate your analysis report. Some of the analyses make take a few minutes to run, and analyses at more specific taxonomic levels (e.g., genus or species) will be slower than analyses at more general taxonomic levels (e.g., phylum, class). \n",
    "\n",
    "**This cell will not run until you fill in a taxonomic level (``2`` through ``7``).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## INDICATE THE PARAMETER IDS FOR YOUR METHOD AS A COMMA-SEPARATED LIST\n",
    "\n",
    "new_param_ids = {'mothur':['confidence']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## project_dir should be the directory where you've downloaded (or cloned) the \n",
    "## short-read-tax-assignment repository. \n",
    "project_dir = expandvars(\"$HOME/data/short-read-tax-assignment\")\n",
    "\n",
    "precomputed_results_dir = expandvars(\"$HOME/data/short-read-tax-assignment/data/precomputed-results/\")\n",
    "expected_results_dir = join(precomputed_results_dir, \"simulated-community\")\n",
    "\n",
    "## results_dirs should contain the directory or directories where\n",
    "## results can be found. By default, this is just the precomputed \n",
    "## results included with the project. If other results should be included, \n",
    "## absolute paths to those directories should be added to this list.\n",
    "results_dirs = \\\n",
    " [precomputed_results_dir,\n",
    "  ]\n",
    "\n",
    "## Taxonomic level at which analyses should be performed. Edit this to\n",
    "## the desired taxonomic level. \n",
    "# 2: phylum, 3: class, 4: order, 5: family, 6: genus, 7: species\n",
    "taxonomic_level = int(environ['taxonomic_level'])\n",
    "\n",
    "## Reference choice (must be partial-ref or full-ref)\n",
    "reference_choice = environ['reference_choice']\n",
    "\n",
    "## Minimum number of times an OTU must be observed for it to be included in analyses. Edit this\n",
    "## to analyze the effect of the minimum count on taxonomic results.\n",
    "min_count = 1\n",
    "\n",
    "# set to true if select tables should be written as Excel files (useful for publication)\n",
    "write_xls_files = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the subdirectories where the data should be, and confirm that they exist.\n",
    "simulated_results_dirs = [join(results_dir,\"simulated-community\") for results_dir in results_dirs]\n",
    "\n",
    "for simulated_results_dir in simulated_results_dirs:\n",
    "    assert exists(simulated_results_dir), \"Simulated community result directory doesn't exist: %s\" % simulated_results_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find pre-computed tables, expected tables, and \"query\" tables\n",
    "-------------------------------------------------------------\n",
    "\n",
    "Next we'll use the paths defined above to find all of the tables that will be compared. These include the *pre-computed result* tables (i.e., the ones that the new methods will be compared to), the *expected result* tables (i.e., the tables containing the known composition of the mock microbial communities), and the *query result* tables (i.e., the tables generated with the new method(s) that we want to compare to the *pre-computed result* tables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for simulated_results_dir in simulated_results_dirs:\n",
    "    results += find_and_process_result_tables(simulated_results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Uncomment for test runs (looks at a small subset of the data)\n",
    "\n",
    "# from random import shuffle\n",
    "# shuffle(results)\n",
    "# results = results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## SPECIFY A NEW NAME FOR YOUR SUMMARY FILE\n",
    "\n",
    "result_fp = join(precomputed_results_dir,'simulated-community', 'level%d-results-w-mothur.csv') % taxonomic_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "if exists(result_fp):\n",
    "    simulated_results = pd.DataFrame.from_csv(result_fp)\n",
    "else:\n",
    "    expected_tables = get_expected_tables_lookup(expected_results_dir, level=taxonomic_level)\n",
    "    simulated_results = compute_mock_results(results, expected_tables, taxonomy_level=taxonomic_level, min_count=min_count)\n",
    "    simulated_results.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "refernece_choice_v = [e.endswith(reference_choice) for e in simulated_results['Parameters']]\n",
    "simulated_results = simulated_results[refernece_choice_v]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evalution 1: Compute and summarize precision, recall, and F-measure\n",
    "-------------------------------------------------------------------\n",
    "\n",
    "In this evaluation, we compute and summarize precision, recall, and F-measure of each result (pre-computed and query) based on the known composition of the simulated communities. We then summarize the results in two ways: first with boxplots, and second with a table of the top methods based on their F-measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-679be1b5f7dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mboxplot_from_data_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimulated_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_by\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Method\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Precision\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/taxcompare/eval_framework.pyc\u001b[0m in \u001b[0;36mboxplot_from_data_frame\u001b[1;34m(df, group_by, metric, y_min, y_max, plotf, color, x_tick_label_rotation)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[0mdistributions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdistribution\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m     \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplotf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbottom\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/seaborn/distributions.pyc\u001b[0m in \u001b[0;36mviolinplot\u001b[1;34m(vals, groupby, inner, color, positions, names, order, bw, widths, alpha, saturation, join_rm, gridsize, cut, inner_kws, ax, vert, **kwargs)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;31m# Reshape and find labels for the plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m     \u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mylabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_box_reshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroupby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;31m# Sort out the plot colors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/seaborn/distributions.pyc\u001b[0m in \u001b[0;36m_box_reshape\u001b[1;34m(vals, groupby, names, order)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;31m# This should catch things like flat lists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m             \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAAFXCAYAAACGDraSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c8a5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot_from_data_frame(simulated_results, group_by=\"Method\", metric=\"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boxplot_from_data_frame(simulated_results, group_by=\"Method\", metric=\"Recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boxplot_from_data_frame(simulated_results, group_by=\"Method\", metric=\"F-measure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boxplot_from_data_frame(simulated_results, group_by=\"Dataset\", metric=\"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boxplot_from_data_frame(simulated_results, group_by=\"Dataset\", metric=\"Recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boxplot_from_data_frame(simulated_results, group_by=\"Dataset\", metric=\"F-measure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "heatmap_from_data_frame(simulated_results, \"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "heatmap_from_data_frame(simulated_results, \"Recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "heatmap_from_data_frame(simulated_results, \"F-measure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "method_by_dataset_a1(simulated_results, 'B1-iter0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "method_by_dataset_a1(simulated_results, 'B2-iter0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "method_by_dataset_a1(simulated_results, 'F1-iter0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "method_by_dataset_a1(simulated_results, 'F2-iter0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation 2: Rank-based statistics comparing the performance of the optimal parameter setting run for each method on each data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Count best* column indicates how many samples a given method achieved within one mean absolute deviation of the best result (which is why they sum to more than the total number of samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Within-method comparisons of parameter performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics = ['Precision', 'Recall', 'F-measure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdp_top_params = parameter_comparisons(simulated_results, \"rdp\", metrics=metrics)\n",
    "rdp_top_params[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uclust_top_params = parameter_comparisons(simulated_results, \"uclust\", metrics=metrics)\n",
    "uclust_top_params[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sortmerna_top_params = parameter_comparisons(simulated_results, \"sortmerna\", metrics=metrics)\n",
    "sortmerna_top_params[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blast_top_params = parameter_comparisons(simulated_results, \"blast\", metrics=metrics)\n",
    "blast_top_params[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## OUTPUT RESULTS FOR YOUR NEW METHOD\n",
    "\n",
    "mothur_top_params = parameter_comparisons(simulated_results, \"mothur\", metrics=metrics)\n",
    "mothur_top_params[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Between-method performance comparisons based on best parameter set determined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sort_field = 'F-measure'\n",
    "display_fields = ['Method', 'Precision', 'Recall', 'F-measure']\n",
    "mp_combs = {}\n",
    "## ADD YOUR METHOD TO THE LIST OF METHODS TO BE COMPARED\n",
    "for e in ['rdp', 'blast', 'sortmerna', 'uclust', 'mothur']:\n",
    "    mp_combs[e] = parameter_comparisons(simulated_results, e, metrics=[sort_field]).index[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "method_by_dataset_iterations(simulated_results, 'B1', mp_combs.items(), sort_field, display_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "method_by_dataset_iterations(simulated_results, 'B2', mp_combs.items(), sort_field, display_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "method_by_dataset_iterations(simulated_results, 'F1', mp_combs.items(), sort_field, display_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "method_by_dataset_iterations(simulated_results, 'F2', mp_combs.items(), sort_field, display_fields)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}