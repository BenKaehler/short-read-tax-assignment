{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novel-taxa and simulated community generation\n",
    "\n",
    "This notebook describes the generation of reference databases for both novel-taxa and simulated community analyses. Novel-taxa analysis is a form of cross-validated taxonomic classification, wherein random unique sequences are sampled from the reference database as a test set; all sequences sharing taxonomic affiliation at a given taxonomic level are removed from the reference database (training set); and taxonomy is assigned to the query sequences at the given taxonomic level. Thus, this test interrogates the behavior of a taxonomy classifier when challenged with \"novel\" sequences that are not represented by close matches within the reference sequence database. Such an analysis is performed to assess the degree to which \"overassignment\" occurs for sequences that are not represented in a reference database.\n",
    "\n",
    "Simulated community analysis represents more conventional cross-validated classification, wherein unique sequences are randomly sampled from a reference dataset and used as a test set for taxonomic classification, using a training set that has those sequences removed, but not other sequences that share taxonomic affiliation. Instead, the training set must contain identical taxonomies to those represented by the test sequences.\n",
    "\n",
    "The general framework for generating a modified reference database for this analysis consists of:\n",
    "\n",
    "1) Novel-taxa reference database generation: Remove empty taxa from ref dbs, split into query/reference subsets.\n",
    "\n",
    "2) Assign taxonomy to \"novel\" query sequences removed from the trimmed reference db to which it is paired.\n",
    "\n",
    "3) Measure rates of classification accuracy for each assignment method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "First step is to create a conda environment with the necessary dependencies. This requires installing [miniconda 3](http://conda.pydata.org/miniconda.html) to manage parallel python environments. After miniconda (or another conda version) is installed, proceed with [installing QIIME 2](https://docs.qiime2.org/2.0.6/install/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions\n",
    "* ``source`` = original reference database.\n",
    "* ``REF`` = ``source`` - ``novel`` seqs, used for taxonomy assignment.\n",
    "* ``QUERY`` = 'novel' query sequences randomly drawn from ``source``. \n",
    "* ``L`` = taxonomic level being tested\n",
    "    * 0 = kingdom, 1 = phylum, 2 = class, 3 = order, 4 = family, 5 = genus, 6 = species\n",
    "* ``branching`` = describes a taxon at level ``L`` that \"branches\" into two or more lineages at ``L + 1``. \n",
    "    * A \"branched\" taxon, then, describes these lineages. E.g., in the example below Lactobacillaceae, Lactobacillus, and Pediococcus branch, while Paralactobacillus is unbranching. The Lactobacillus and Pediococcus species are \"branched\". Paralactobacillus selangorensis is \"unbranched\"\n",
    "\n",
    "```\n",
    "Lactobacillaceae\n",
    "           └── Lactobacillus\n",
    "           │         ├── Lactobacillus brevis\n",
    "           │         └── Lactobacillus sanfranciscensis\n",
    "           ├── Pediococcus\n",
    "           │         ├── Pediococcus damnosus\n",
    "           │         └── Pediococcus claussenii\n",
    "           └── Paralactobacillus\n",
    "                     └── Paralactobacillus selangorensis\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novel-taxa reference data set generation\n",
    "\n",
    "This section describes the preparation of the data sets necessary for \"novel taxa\" analysis. The goals of this step are:\n",
    "1. Create a \"clean\" reference database that can be used for evaluation of \"novel taxa\" from phylum to species level.\n",
    "2. Generate simulated amplicons and randomly subsample query sequences to use as \"novel taxa\"\n",
    "3. Create modified sequence reference databases for taxonomic classification of \"novel taxa\" sequences\n",
    "\n",
    "In this first cell, we describe data set/database characteristics as a dictionary: dataset name is the key, with values reference sequence fasta, taxonomy, database name, forward primer sequence, reverse primer sequence, forward primer name, reverse primer name.\n",
    "\n",
    "MODIFY these values to generate novel-taxa files on a new reference database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tax_credit.taxa_manipulator import *\n",
    "from tax_credit.framework_functions import *\n",
    "\n",
    "from os import path, makedirs, remove, rename\n",
    "from os.path import expandvars, exists, basename, splitext, dirname, join, isfile\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "from skbio.util import create_dir\n",
    "from skbio.alignment import global_pairwise_align_nucleotide, make_identity_substitution_matrix, local_pairwise_align_ssw\n",
    "from skbio.sequence import DNA\n",
    "from skbio import io, DNA\n",
    "from shutil import copyfile\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project_dir = expandvars(\"$HOME/Desktop/projects/short-read-tax-assignment\")\n",
    "data_dir = join(project_dir, \"data\")\n",
    "\n",
    "# List databases as fasta/taxonomy file pairs\n",
    "databases = {'B1-REF': [expandvars(\"$HOME/Desktop/ref_dbs/gg_13_8_otus/rep_set/97_otus.fasta\"), \n",
    "             expandvars(\"$HOME/Desktop/ref_dbs/gg_13_8_otus/taxonomy/97_otu_taxonomy.txt\"),\n",
    "             \"gg_13_8_otus\", \"GTGCCAGCMGCCGCGGTAA\", \"ATTAGAWACCCBDGTAGTCC\", \"515F\", \"806R\"],\n",
    "             'F1-REF': [expandvars(\"$HOME/Desktop/ref_dbs/unite-97-rep-set/97_otus.txt\"), \n",
    "             expandvars(\"$HOME/Desktop/ref_dbs/unite-97-rep-set/97_otu_taxonomy.txt\"), \n",
    "             \"unite-97-rep-set\", \"ACCTGCGGARGGATCA\", \"AACTTTYARCAAYGGAT\", \"BITSf\", \"B58S3r\"]\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will import these to a dataframe and view it. You should not need to modify the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reference file path</th>\n",
       "      <th>Reference tax path</th>\n",
       "      <th>Reference id</th>\n",
       "      <th>Fwd primer</th>\n",
       "      <th>Rev primer</th>\n",
       "      <th>Fwd primer id</th>\n",
       "      <th>Rev primer id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1-REF</th>\n",
       "      <td>/Users/nbokulich/Desktop/ref_dbs/unite-97-rep-...</td>\n",
       "      <td>/Users/nbokulich/Desktop/ref_dbs/unite-97-rep-...</td>\n",
       "      <td>unite-97-rep-set</td>\n",
       "      <td>ACCTGCGGARGGATCA</td>\n",
       "      <td>AACTTTYARCAAYGGAT</td>\n",
       "      <td>BITSf</td>\n",
       "      <td>B58S3r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B1-REF</th>\n",
       "      <td>/Users/nbokulich/Desktop/ref_dbs/gg_13_8_otus/...</td>\n",
       "      <td>/Users/nbokulich/Desktop/ref_dbs/gg_13_8_otus/...</td>\n",
       "      <td>gg_13_8_otus</td>\n",
       "      <td>GTGCCAGCMGCCGCGGTAA</td>\n",
       "      <td>ATTAGAWACCCBDGTAGTCC</td>\n",
       "      <td>515F</td>\n",
       "      <td>806R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Reference file path  \\\n",
       "F1-REF  /Users/nbokulich/Desktop/ref_dbs/unite-97-rep-...   \n",
       "B1-REF  /Users/nbokulich/Desktop/ref_dbs/gg_13_8_otus/...   \n",
       "\n",
       "                                       Reference tax path      Reference id  \\\n",
       "F1-REF  /Users/nbokulich/Desktop/ref_dbs/unite-97-rep-...  unite-97-rep-set   \n",
       "B1-REF  /Users/nbokulich/Desktop/ref_dbs/gg_13_8_otus/...      gg_13_8_otus   \n",
       "\n",
       "                 Fwd primer            Rev primer Fwd primer id Rev primer id  \n",
       "F1-REF     ACCTGCGGARGGATCA     AACTTTYARCAAYGGAT         BITSf        B58S3r  \n",
       "B1-REF  GTGCCAGCMGCCGCGGTAA  ATTAGAWACCCBDGTAGTCC          515F          806R  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arrange data set / database info in data frame\n",
    "simulated_community_definitions = pd.DataFrame.from_dict(databases, orient=\"index\")\n",
    "simulated_community_definitions.columns = [\"Reference file path\", \"Reference tax path\", \"Reference id\", \n",
    "                                           \"Fwd primer\", \"Rev primer\", \"Fwd primer id\", \"Rev primer id\"]\n",
    "simulated_community_definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate \"clean\" reference taxonomy and sequence database by removing taxonomy strings with empty or ambiguous levels'\n",
    "\n",
    "Set simulated community parameters, including amplicon length and the number of iterations to perform. Iterations will split our query sequence files into N chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-REF Sequence Counts\n",
      "Raw Fasta:            29435.0\n",
      "Clean Fasta:          20415.0\n",
      "Simulated Amplicons:  18085.0\n",
      "Simulated Reads:      12269.0\n",
      "F1-REF level 6 contains 8156 unique and 7276 branched taxa              \n",
      "F1-REF level 5 contains 1746 unique and 1601 branched taxa              \n",
      "F1-REF level 4 contains 377 unique and 315 branched taxa              \n",
      "F1-REF level 3 contains 119 unique and 98 branched taxa              \n",
      "F1-REF level 2 contains 34 unique and 30 branched taxa              \n",
      "F1-REF level 1 contains 7 unique and 7 branched taxa              \n",
      "B1-REF Sequence Counts\n",
      "Raw Fasta:            99322.0\n",
      "Clean Fasta:          6138.0\n",
      "Simulated Amplicons:  6107.0\n",
      "Simulated Reads:      6106.0\n",
      "B1-REF level 6 contains 1922 unique and 1075 branched taxa              \n",
      "B1-REF level 5 contains 1111 unique and 1021 branched taxa              \n",
      "B1-REF level 4 contains 252 unique and 183 branched taxa              \n",
      "B1-REF level 3 contains 114 unique and 71 branched taxa              \n",
      "B1-REF level 2 contains 61 unique and 45 branched taxa              \n",
      "B1-REF level 1 contains 27 unique and 27 branched taxa              \n"
     ]
    }
   ],
   "source": [
    "read_length = 250\n",
    "iterations = 3\n",
    "generate_simulated_datasets(simulated_community_definitions, data_dir, read_length, iterations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For peace of mind, we can test our novel taxa and simulated community datasets to confirm that:\n",
    "\n",
    "1) For simulated communities, test (query) taxa IDs are not in training (ref) set, but all taxonomy strings are\n",
    "\n",
    "2) For novel taxa, test taxa IDs and taxonomies are not in training (ref) set, but sister branch taxa are\n",
    "\n",
    "If no errors print, all tests pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_simulated_communities(simulated_community_definitions, data_dir, iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, confirm that novel taxa were generated successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_novel_taxa_datasets(simulated_community_definitions, data_dir, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
