{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mock community dataset generation\n",
    "This notebook describes how mock community datasets were retrieved and files were generated for tax-credit comparisons. Only the feature tables, metadata maps, representative sequences, and expected taxonomies are included in tax-credit, but this notebook can regenerate intermediate files, generate these files for new mock communities, or tweaked to benchmark, e.g., quality control or OTU picking methods.\n",
    "\n",
    "All mock communities are hosted on [mockrobiota](http://caporasolab.us/mockrobiota/), though raw reads are deposited elsewhere. To use these mock communities, clone the ``mockrobiota`` repository into the ``repo_dir`` that contains the tax-credit repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tax_credit.process_mocks import *\n",
    "\n",
    "from os import path, makedirs, remove, rename\n",
    "from os.path import expandvars, exists, basename, splitext, dirname, join, isfile\n",
    "from shutil import copyfile\n",
    "import biom\n",
    "\n",
    "import qiime\n",
    "from qiime.plugins import feature_table, demux, dada2, alignment, phylogeny\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set source/destination filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# base directory containing tax-credit and mockrobiota repositories\n",
    "repo_dir = expandvars(\"$HOME/Desktop/projects/\")\n",
    "# tax-credit directory\n",
    "project_dir = join(repo_dir, \"short-read-tax-assignment\")\n",
    "# mockrobiota directory\n",
    "mockrobiota_dir = join(repo_dir, \"mockrobiota\")\n",
    "# temp destination for mock community files\n",
    "mock_data_dir = join(repo_dir, \"mock-community\")\n",
    "# destination for expected taxonomy assignments\n",
    "expected_data_dir = join(project_dir, \"data\", \"precomputed-results\", \"mock-community\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will define which mock communities we plan to use, and necessary parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will just use a sequential set of mockrobiota datasets, otherwise list community names manually\n",
    "communities = ['mock-{0}'.format(n) for n in range(1,11)]\n",
    "\n",
    "# Create dictionary of mock community dataset metadata\n",
    "community_metadata = extract_mockrobiota_dataset_metadata(mockrobiota_dir, communities)\n",
    "\n",
    "# Map marker-gene to reference database names in tax-credit and in mockrobiota\n",
    "#           marker-gene  tax-credit-dir  mockrobiota-dir version\n",
    "reference_dbs = {'16S' : ('gg_13_8_otus', 'greengenes', '13_8'),\n",
    "                 'ITS' : ('unite-97-rep-set', 'unite', '97')\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will generate data directories in ``tax-credit`` for each community and begin populating these will files from ``mockrobiota``. This may take some time, as this involves downloading raw data fastq files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extract_mockrobiota_data(communities, community_metadata, reference_dbs, \n",
    "                         mockrobiota_dir, mock_data_dir, \n",
    "                         expected_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data in QIIME2\n",
    "Finally, we can get to processing our data. We begin by importing our data, demultiplexing, and viewing a few fastq quality summaries to decide how to trim our raw reads prior to processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Importing 'EMPMultiplexedDirFmt' requires a directory, not /Users/nbokulich/Desktop/projects/mock-community/mock-3/mock-forward-read.fastq.gz",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-6daf900125fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# import fastq to qiime artifact\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#qiime tools import --type  --input-path $raw_dir --output-path $projectdir/raw-sequences.qza\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mforward_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqiime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArtifact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RawSequences\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_read_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mindex_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqiime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArtifact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RawSequences\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_read_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nbokulich/miniconda3/envs/qiime2-05/lib/python3.5/site-packages/qiime-2.0.6-py3.5.egg/qiime/sdk/result.py\u001b[0m in \u001b[0;36mimport_data\u001b[0;34m(cls, type, view, view_type)\u001b[0m\n\u001b[1;32m    169\u001b[0m                         raise ValueError(\"Importing %r requires a\"\n\u001b[1;32m    170\u001b[0m                                          \u001b[0;34m\" directory, not %s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                                          % (output_dir_fmt.__name__, view))\n\u001b[0m\u001b[1;32m    172\u001b[0m                     \u001b[0mview_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_dir_fmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Importing 'EMPMultiplexedDirFmt' requires a directory, not /Users/nbokulich/Desktop/projects/mock-community/mock-3/mock-forward-read.fastq.gz"
     ]
    }
   ],
   "source": [
    "for community in communities[2:3]:\n",
    "    # extract dataset metadata/params\n",
    "    community_dir = join(mock_data_dir, community)\n",
    "    marker_gene = community_metadata[community][2]\n",
    "    forward_read_fp = join(community_dir,'mock-forward-read.fastq.gz')\n",
    "    index_read_fp = join(community_dir,'mock-index-read.fastq.gz')\n",
    "    sample_metadata = join(community_dir, 'sample-metadata.tsv')\n",
    "    \n",
    "    # import fastq to qiime artifact\n",
    "    #qiime tools import --type  --input-path $raw_dir --output-path $projectdir/raw-sequences.qza\n",
    "    forward_read = qiime.Artifact.import_data(\"RawSequences\", forward_read_fp)\n",
    "    index_read = qiime.Artifact.import_data(\"RawSequences\", index_read_fp)\n",
    "\n",
    "    # demultiplex / QC\n",
    "    #qiime demux emp --i-seqs $projectdir/raw-sequences.qza --m-barcodes-file $demuxmap --m-barcodes-category BarcodeSequence --o-per-sample-sequences $projectdir/demux --p-rev-comp-barcodes\n",
    "    demux_seqs = demux.methods.emp(seqs = forward_read,\n",
    "                                   barcodes_file = index_read,\n",
    "                                   barcodes_category = 'BarcodeSequence',\n",
    "                                   per_sample_sequences = join(community_dir, 'demux-seqs.qza'),\n",
    "                                   rev_comp_barcodes = True)\n",
    "    \n",
    "    # demultiplexing summary\n",
    "    #qiime demux summarize --i-data $projectdir/demux.qza --o-visualization $projectdir/demux-summary\n",
    "    demux_summary = demux.methods.summarize(data = demux_seqs,\n",
    "                                            visualization = join(community_dir, \n",
    "                                                                 'demux_summary.qzv')\n",
    "                                           )\n",
    "\n",
    "    # view fastq quality plots\n",
    "    #qiime dada2 plot-qualities --i-demultiplexed-seqs $projectdir/demux.qza --o-visualization $projectdir/demux-qual-plots --p-n 5\n",
    "    demux_plot_qual = dada2.methods.plot_qualities(demultiplexed_seqs = demux_seqs,\n",
    "                                                   visualization = join(community_dir,\n",
    "                                                                        'demux_plot_qual.qzv'),\n",
    "                                                   n = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for community in communities:\n",
    "    tools.methods.view(join(mock_data_dir, community, 'demux_summary.qzv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for community in communities:\n",
    "    tools.methods.view(join(mock_data_dir, community, 'demux_plot_qual.qzv'))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the quality data above to decide how to proceed. As each dataset will have different quality profiles and read lengths, we will enter trimming parameters as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# {community : (trim_left, trunc_len)}\n",
    "trim_params = {'mock-1' : (left, right)\n",
    "               'mock-2' : ()\n",
    "               'mock-3' : ()\n",
    "               'mock-4' : ()\n",
    "               'mock-5' : ()\n",
    "               'mock-6' : ()\n",
    "               'mock-7' : ()\n",
    "               'mock-8' : ()\n",
    "               'mock-9' : ()\n",
    "               'mock-10' : ()\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will quality filter with ``dada2``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for community in communities:\n",
    "    community_dir = join(mock_data_dir, community)\n",
    "    \n",
    "    # dada2\n",
    "    #qiime dada2 denoise --i-demultiplexed-seqs $projectdir/demux.qza --p-trim-left 10 --p-trunc-len 90 --o-representative-sequences $projectdir/rep-seqs --o-table $projectdir/table\n",
    "    dada2.methods.denoise(demultiplexed_seqs = join(community_dir, 'demux-seqs.qza'),\n",
    "                          trim_left = trim_params[community][0],\n",
    "                          trunc_len = trim_params[community][1],\n",
    "                          representative_sequences = join(community_dir, 'rep_seqs.qza'),\n",
    "                          table = join(community_dir, 'feature_table.qza')\n",
    "                         )\n",
    "\n",
    "    # summarize feature table\n",
    "    #qiime feature-table summarize --i-table $projectdir/table.qza --o-visualization $projectdir/table\n",
    "    feature_table.methods.summarize(table = join(community_dir, 'feature_table.qza'),\n",
    "                                    visualization = join(community_dir, 'feature_table_summary.qzv')\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for community in communities:\n",
    "    tools.methods.view(join(mock_data_dir, community, 'feature_table_summary.qzv'))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, build a phylogeny from rep sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for community in communities:\n",
    "    community_dir = join(mock_data_dir, community)\n",
    "    \n",
    "    # Build phylogeny\n",
    "    #qiime alignment mafft --i-sequences $projectdir/rep-seqs.qza --o-alignment $projectdir/aligned-rep-seqs\n",
    "    aligned_seqs = alignment.methods.mafft(join(community_dir, 'rep_seqs.qza'))\n",
    "    \n",
    "    #qiime alignment mask --i-alignment $projectdir/aligned-rep-seqs.qza --o-masked-alignment $projectdir/masked-aligned-rep-seqs\n",
    "    masked_alignment = alignment.methods.mask(aligned_seqs)\n",
    "\n",
    "    #qiime phylogeny fasttree --i-alignment $projectdir/masked-aligned-rep-seqs.qza --o-tree $projectdir/unrooted-tree\n",
    "    unrooted_tree = phylogeny.methods.fasttree(masked_alignment)\n",
    "    \n",
    "    #qiime phylogeny midpoint-root --i-tree $projectdir/unrooted-tree.qza --o-rooted-tree $projectdir/rooted-tree\n",
    "    tree = phylogeny.methods.midpoint_root(tree = unrooted_tree,\n",
    "                                          rooted_tree = join(community_dir, 'phylogeny.qza'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract results and move to repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mock community data: feature_table, sample_metadata, rep_seqs, tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for community in communities:\n",
    "    \n",
    "    # Define base dir destination for mock community directories\n",
    "    repo_destination = join(project_dir, \"data\", \"mock-community\")\n",
    "    \n",
    "    # Files to move\n",
    "    rep_seqs = join(community_dir, 'rep_seqs.qza')\n",
    "    feature_table = join(community_dir, 'feature_table.qza')\n",
    "    tree = join(community_dir, 'phylogeny.qza')\n",
    "    sample_md = join(community_dir, 'sample-metadata.tsv')\n",
    "    biom_table_fp = join(community_dir, 'feature_table.biom')\n",
    "    \n",
    "    # Extract biom, tree, rep_seqs\n",
    "    biom_table = feature_table.view(biom.Table)\n",
    "    write_biom_table(biom_table, 'hdf5', biom_table_fp)\n",
    "\n",
    "    # Extract feature_table to biom\n",
    "    # Extract rep_seq to fasta\n",
    "    # Move to repo:\n",
    "    for file in [rep_seqs, feature_table, tree, sample_md, biom_table_fp, ]:\n",
    "        copyfile(file, join(repo_destination, community, basename(file)))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List databases as fasta/taxonomy file pairs\n",
    "databases = {'B1-REF': [expandvars(\"$HOME/Desktop/ref_dbs/gg_13_8_otus/rep_set/97_otus.fasta\"), \n",
    "             expandvars(\"$HOME/Desktop/ref_dbs/gg_13_8_otus/taxonomy/97_otu_taxonomy.txt\"),\n",
    "             \"gg_13_8_otus\", \"GTGCCAGCMGCCGCGGTAA\", \"ATTAGAWACCCBDGTAGTCC\", \"515F\", \"806R\"],\n",
    "             'F1-REF': [expandvars(\"$HOME/Desktop/ref_dbs/unite-97-rep-set/97_otus.txt\"), \n",
    "             expandvars(\"$HOME/Desktop/ref_dbs/unite-97-rep-set/97_otu_taxonomy.txt\"), \n",
    "             \"unite-97-rep-set\", \"ACCTGCGGARGGATCA\", \"AACTTTYARCAAYGGAT\", \"BITSf\", \"B58S3r\"]\n",
    "            }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
