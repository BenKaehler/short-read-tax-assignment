{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mock community dataset generation\n",
    "\n",
    "Run in a [qiime 2.0.6 conda environment](https://docs.qiime2.org/2.0.6/install/).\n",
    "\n",
    "This notebook describes how mock community datasets were retrieved and files were generated for tax-credit comparisons. Only the feature tables, metadata maps, representative sequences, and expected taxonomies are included in tax-credit, but this notebook can regenerate intermediate files, generate these files for new mock communities, or tweaked to benchmark, e.g., quality control or OTU picking methods.\n",
    "\n",
    "All mock communities are hosted on [mockrobiota](http://caporasolab.us/mockrobiota/), though raw reads are deposited elsewhere. To use these mock communities, clone the ``mockrobiota`` repository into the ``repo_dir`` that contains the tax-credit repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tax_credit.process_mocks import *\n",
    "\n",
    "from os import path, makedirs, remove, rename\n",
    "from os.path import expandvars, exists, basename, splitext, dirname, join, isfile\n",
    "from shutil import copyfile\n",
    "import biom\n",
    "from biom.cli.util import write_biom_table\n",
    "\n",
    "import qiime\n",
    "from qiime.plugins import feature_table, demux, dada2, alignment, phylogeny\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set source/destination filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# base directory containing tax-credit and mockrobiota repositories\n",
    "repo_dir = expandvars(\"$HOME/Desktop/projects/\")\n",
    "# tax-credit directory\n",
    "project_dir = join(repo_dir, \"short-read-tax-assignment\")\n",
    "# mockrobiota directory\n",
    "mockrobiota_dir = join(repo_dir, \"mockrobiota\")\n",
    "# temp destination for mock community files\n",
    "mock_data_dir = join(repo_dir, \"mock-community\")\n",
    "# destination for expected taxonomy assignments\n",
    "expected_data_dir = join(project_dir, \"data\", \"precomputed-results\", \"mock-community\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will define which mock communities we plan to use, and necessary parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will just use a sequential set of mockrobiota datasets, otherwise list community names manually\n",
    "communities = ['mock-{0}'.format(n) for n in range(1,11)]\n",
    "\n",
    "# Create dictionary of mock community dataset metadata\n",
    "community_metadata = extract_mockrobiota_dataset_metadata(mockrobiota_dir, communities)\n",
    "\n",
    "# Map marker-gene to reference database names in tax-credit and in mockrobiota\n",
    "#           marker-gene  tax-credit-dir  mockrobiota-dir version\n",
    "reference_dbs = {'16S' : ('gg_13_8_otus', 'greengenes', '13_8'),\n",
    "                 'ITS' : ('unite-97-rep-set', 'unite', '97')\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will generate data directories in ``tax-credit`` for each community and begin populating these will files from ``mockrobiota``. This may take some time, as this involves downloading raw data fastq files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extract_mockrobiota_data(communities, community_metadata, reference_dbs, \n",
    "                         mockrobiota_dir, mock_data_dir, \n",
    "                         expected_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data in QIIME2\n",
    "Finally, we can get to processing our data. We begin by importing our data, demultiplexing, and viewing a few fastq quality summaries to decide how to trim our raw reads prior to processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dataset may require different parameters. For example, some mock communities used here require different barcode orientations. These parameters may be read in as a dictionary of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# {community : (rev_comp_barcodes, rev_comp_mapping_barcodes)}\n",
    "demux_params = {'mock-1' : (False, True),\n",
    "               'mock-2' : (False, True),\n",
    "               'mock-3' : (False, False),\n",
    "               'mock-4' : (False, True),\n",
    "               'mock-5' : (False, True),\n",
    "               'mock-6' : (False, True),\n",
    "               'mock-7' : (False, True),\n",
    "               'mock-8' : (False, True),\n",
    "               'mock-9' : (False, True),\n",
    "               'mock-10' : (False, True)\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running external command line application(s). This may print messages to stdout and/or stderr.\n",
      "The command(s) being run are below. These commands cannot be manually re-run as they will depend on temporary files that no longer exist.\n",
      "\n",
      "Command: profile_quality.R /var/folders/0t/l1dz88p50y91vx_22fx5w3780000gn/T/qiime2-archive-46vxmj3v/8ae9f3dc-8e4f-47e2-834b-75bbfac317f1/data/HMPMockV1.2.Staggered2_4_L001_R1_001.fastq.gz /var/folders/0t/l1dz88p50y91vx_22fx5w3780000gn/T/qiime2-temp-y9urhpgi\n",
      "\n",
      "mock-3 complete\n"
     ]
    }
   ],
   "source": [
    "batch_demux(communities[2:3], mock_data_dir, demux_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the summaries you just created, drag and drop the files into [q2view](https://view.qiime2.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the fastq quality data above to decide how to proceed. As each dataset will have different quality profiles and read lengths, we will enter trimming parameters as a dictionary. We can use this dict to pass other parameters to ``denoise_to_phylogeny()``, including whether we want to build a phylogeny for each community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# {community : (trim_left, trunc_len, build_phylogeny)}\n",
    "trim_params = {'mock-1' : (0, 100, True),\n",
    "               'mock-2' : (0, 130, True),\n",
    "               'mock-3' : (0, 150, True),\n",
    "               'mock-4' : (0, 150, True),\n",
    "               'mock-5' : (0, 200, True),\n",
    "               'mock-6' : (0, 50, True),\n",
    "               'mock-7' : (0, 90, True),\n",
    "               'mock-8' : (0, 100, True),\n",
    "               'mock-9' : (0, 100, False),\n",
    "               'mock-10' : (0, 100, False)\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will quality filter with ``dada2``, and use the representative sequences to generate a phylogeny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running external command line application(s). This may print messages to stdout and/or stderr.\n",
      "The command(s) being run are below. These commands cannot be manually re-run as they will depend on temporary files that no longer exist.\n",
      "\n",
      "Command: run_dada.R /var/folders/0t/l1dz88p50y91vx_22fx5w3780000gn/T/qiime2-archive-yy2wiw0u/d6db247c-3690-41fb-b56c-07120727b815/data /var/folders/0t/l1dz88p50y91vx_22fx5w3780000gn/T/tmpc5ewyppv/output.tsv.biom 150 0 2 2 /var/folders/0t/l1dz88p50y91vx_22fx5w3780000gn/T/tmpc5ewyppv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "denoise_to_phylogeny(communities[3:], mock_data_dir, trim_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the summaries you just created, drag and drop the files into [q2view](https://view.qiime2.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract results and move to repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mock community data: feature_table, sample_metadata, rep_seqs, tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<artifact: FeatureData[Sequence] uuid: 2e2e1d61-07c5-4cc2-b4cc-59cba716b90c>\n"
     ]
    }
   ],
   "source": [
    "rep_seqs_fna = qiime.Artifact.load(rep_seqs)\n",
    "print(rep_seqs_fna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import q2_types\n",
    "import pandas as pd\n",
    "outfile = '/Users/nbokulich/Desktop/projects/mock-community/mock-3/test.fna'\n",
    "aview = a.view(view_type=q2_types.feature_data._transformer.DNAIterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "less /Users/nbokulich/miniconda3/envs/qiime2-06/lib/python3.5/site-packages/q2_types-0.0.6-py3.5.egg/q2_types/feature_data/_transformer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([<class 'pandas.core.series.Series'>, <class 'q2_types.feature_data._transformer.DNAIterator'>])\n"
     ]
    }
   ],
   "source": [
    "from qiime.sdk import Artifact, PluginManager\n",
    "from qiime.plugin.model import SingleFileDirectoryFormatBase\n",
    "\n",
    "rep_seqs = '/Users/nbokulich/Desktop/projects/mock-community/mock-3/rep_seqs.qza'\n",
    "\n",
    "pm = PluginManager()\n",
    "a = qiime.Artifact.load(rep_seqs)\n",
    "to_views = None\n",
    "\n",
    "if issubclass(a.format, SingleFileDirectoryFormatBase):\n",
    "    to_views = pm.transformers.get(a.format.file.format)\n",
    "elif a.format in transformers:\n",
    "    to_views = transformers.get(a.format)\n",
    "\n",
    "if to_views is not None:\n",
    "    print(to_views.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "No transformation from <class 'qiime.plugin.model.directory_format.DNASequencesDirectoryFormat'> to <class 'str'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-567dbc443121>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mbiom_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqiime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArtifact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbiom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mwrite_biom_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbiom_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hdf5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiom_table_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mrep_seqs_fna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqiime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArtifact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep_seqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mrep_seqs_fna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep_seqs_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mphylogeny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqiime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArtifact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep_seqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nbokulich/miniconda3/envs/qiime2-06/lib/python3.5/site-packages/qiime-2.0.6-py3.5.egg/qiime/sdk/result.py\u001b[0m in \u001b[0;36mview\u001b[0;34m(self, view_type)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mview_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecorder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nbokulich/miniconda3/envs/qiime2-06/lib/python3.5/site-packages/qiime-2.0.6-py3.5.egg/qiime/sdk/result.py\u001b[0m in \u001b[0;36m_view\u001b[0;34m(self, view_type, recorder)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         transformation = from_type.make_transformation(to_type,\n\u001b[0;32m--> 233\u001b[0;31m                                                        recorder=recorder)\n\u001b[0m\u001b[1;32m    234\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_archiver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nbokulich/miniconda3/envs/qiime2-06/lib/python3.5/site-packages/qiime-2.0.6-py3.5.egg/qiime/core/transform.py\u001b[0m in \u001b[0;36mmake_transformation\u001b[0;34m(self, other, recorder)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransformer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             raise Exception(\"No transformation from %r to %r\" %\n\u001b[0;32m---> 53\u001b[0;31m                             (self._view_type, other._view_type))\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mtransformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: No transformation from <class 'qiime.plugin.model.directory_format.DNASequencesDirectoryFormat'> to <class 'str'>"
     ]
    }
   ],
   "source": [
    "for community in communities[2:3]:\n",
    "    community_dir = join(mock_data_dir, community)\n",
    "\n",
    "    # Define base dir destination for mock community directories\n",
    "    repo_destination = join(project_dir, \"data\", \"mock-community\", community)\n",
    "    if not exists(repo_destination):\n",
    "        makedirs(repo_destination)\n",
    "    \n",
    "    # Files to move\n",
    "    rep_seqs = join(community_dir, 'rep_seqs.qza')\n",
    "    feature_table = join(community_dir, 'feature_table.qza')\n",
    "    tree = join(community_dir, 'phylogeny.qza')\n",
    "    sample_md = join(community_dir, 'sample-metadata.tsv')\n",
    "    \n",
    "    biom_table_fp = join(community_dir, 'feature_table.biom')\n",
    "    rep_seqs_fp = join(community_dir, 'rep_seqs.fna')\n",
    "    tree_fp = join(community_dir, 'phylogeny.tre')\n",
    "\n",
    "    # Extract biom, tree, rep_seqs\n",
    "    biom_table = qiime.Artifact.load(feature_table).view(biom.Table)\n",
    "    write_biom_table(biom_table, 'hdf5', biom_table_fp)\n",
    "    rep_seqs_fna = qiime.Artifact.load(rep_seqs).view(str)\n",
    "    rep_seqs_fna.save(rep_seqs_fp)\n",
    "    phylogeny = qiime.Artifact.load(rep_seqs).view(str)\n",
    "    phylogeny.save(tree_fp)\n",
    "\n",
    "    # Move to repo:\n",
    "    for file in [rep_seqs, feature_table, tree, sample_md, biom_table_fp, rep_seqs_fp, tree_fp]:\n",
    "        copyfile(file, join(repo_destination, basename(file)))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List databases as fasta/taxonomy file pairs\n",
    "databases = {'B1-REF': [expandvars(\"$HOME/Desktop/ref_dbs/gg_13_8_otus/rep_set/97_otus.fasta\"), \n",
    "             expandvars(\"$HOME/Desktop/ref_dbs/gg_13_8_otus/taxonomy/97_otu_taxonomy.txt\"),\n",
    "             \"gg_13_8_otus\", \"GTGCCAGCMGCCGCGGTAA\", \"ATTAGAWACCCBDGTAGTCC\", \"515F\", \"806R\"],\n",
    "             'F1-REF': [expandvars(\"$HOME/Desktop/ref_dbs/unite-97-rep-set/97_otus.txt\"), \n",
    "             expandvars(\"$HOME/Desktop/ref_dbs/unite-97-rep-set/97_otu_taxonomy.txt\"), \n",
    "             \"unite-97-rep-set\", \"ACCTGCGGARGGATCA\", \"AACTTTYARCAAYGGAT\", \"BITSf\", \"B58S3r\"]\n",
    "            }"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:qiime2-06]",
   "language": "python",
   "name": "conda-env-qiime2-06-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
