{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import tempfile\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "import csv\n",
    "import io\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "import skbio\n",
    "import qiime2\n",
    "from qiime2.plugins.feature_classifier.methods import extract_reads\n",
    "from q2_types.feature_data import DNAIterator\n",
    "import pandas\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.expanduser('~/Projects/short-read-tax-assignment-bk/data')\n",
    "mockrobiota_dir = os.path.expanduser('~/Projects/mockrobiota/data')\n",
    "ref_dir = os.path.expanduser('~/Data')\n",
    "mock_dir = os.path.join(data_dir, 'mock-community')\n",
    "expected_dir = os.path.join(data_dir, 'precomputed-results', 'mock-community')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ref_dbs = [('greengenes',\n",
    "            os.path.join(ref_dir, 'gg_13_8_otus', 'rep_set', '99_otus.fasta'),\n",
    "            os.path.join(ref_dir, 'gg_13_8_otus', 'taxonomy', '99_otu_taxonomy.txt')),\n",
    "           ('unite',\n",
    "            os.path.join(ref_dir, 'unite_7_1', 'developer', 'sh_refs_qiime_ver7_99_20.11.2016_dev.fasta'),\n",
    "            os.path.join(ref_dir, 'unite_7_1', 'developer', 'sh_taxonomy_qiime_ver7_99_20.11.2016_dev.txt'))]\n",
    "\n",
    "refs = {}\n",
    "taxs = {}\n",
    "for ref_name, db_file, tax_file in ref_dbs:\n",
    "    seqs = skbio.io.read(db_file, format='fasta', constructor=skbio.DNA)\n",
    "    refs[ref_name] = list(seqs)\n",
    "    tax_map = {}\n",
    "    with open(tax_file) as tax_fh:\n",
    "        reader = csv.reader(tax_fh, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            tax_map[row[0]] = row[1]\n",
    "        taxs[ref_name] = tax_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def single_character_matches(char, query, subject):\n",
    "    query = ((query == char) + (query == 'N')).astype(int)\n",
    "    subject = ((subject == char) + (subject == 'N')).astype(int)\n",
    "    return numpy.convolve(query[::-1], subject)\n",
    "\n",
    "    \n",
    "def gapless_mismatches(query, subject):\n",
    "    matches = single_character_matches('A', query, subject)\n",
    "    matches += single_character_matches('C', query, subject)\n",
    "    matches += single_character_matches('G', query, subject)\n",
    "    matches += single_character_matches('T', query, subject)\n",
    "    return len(query) - matches.max()\n",
    "\n",
    "\n",
    "def compare_observed_and_expected(observed, expected):\n",
    "    ids = [obs.metadata['id'] for obs in observed]\n",
    "    rev_observed = [numpy.array(list(str(obs.reverse_complement()))) for obs in observed]\n",
    "    observed = [numpy.array(list(str(obs))) for obs in observed]\n",
    "    expected = list(expected)\n",
    "    keys = [' '.join([exp.metadata['id'], exp.metadata['description']]).strip() for exp in expected]\n",
    "    expected = [numpy.array(list(str(exp))) for exp in expected]\n",
    "    comparison = {}\n",
    "    for _id, obs, rev in zip(ids, observed, rev_observed):\n",
    "        forward = min([(gapless_mismatches(obs, exp), key) for exp, key in zip(expected, keys)])\n",
    "        reverse = min([(gapless_mismatches(rev, exp), key) for exp, key in zip(expected, keys)])\n",
    "        comparison[_id] = min(forward, reverse)\n",
    "    return comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish expected sequences and taxonomies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mock-1\n",
      "mock-10\n",
      "mock-12\n",
      "mock-13\n",
      "mock-14\n",
      "mock-15\n",
      "mock-16\n",
      "mock-2\n",
      "mock-3\n",
      "mock-4\n",
      "mock-5\n",
      "mock-6\n",
      "mock-7\n",
      "mock-8\n",
      "mock-9\n"
     ]
    }
   ],
   "source": [
    "for com_dir in glob.glob(os.path.join(expected_dir, '*')):\n",
    "    if not os.path.isdir(com_dir):\n",
    "        continue\n",
    "    community = os.path.basename(com_dir)\n",
    "    this_mock_dir = os.path.join(mock_dir, community)\n",
    "    \n",
    "    # mock-3 to -5 use the same sequences as mock-13\n",
    "    if community in ('mock-3', 'mock-4', 'mock-5'):\n",
    "        this_mockrobiota_dir = os.path.join(mockrobiota_dir, 'mock-13')\n",
    "    else:\n",
    "        this_mockrobiota_dir = os.path.join(mockrobiota_dir, community)\n",
    "    \n",
    "    # find the expected taxonomies\n",
    "    if os.path.exists(os.path.join(this_mockrobiota_dir, 'greengenes')):\n",
    "        identifier_file_dir = os.path.join(this_mockrobiota_dir, 'greengenes', '13-8', '99-otus')\n",
    "        ref_seqs = refs['greengenes']\n",
    "        taxonomy_map = taxs['greengenes']\n",
    "    elif os.path.exists(os.path.join(this_mockrobiota_dir, 'unite')):\n",
    "        identifier_file_dir = os.path.join(this_mockrobiota_dir, 'unite', '7-1', '99-otus')\n",
    "        ref_seqs = refs['unite']\n",
    "        taxonomy_map = taxs['unite']\n",
    "    else:\n",
    "        raise RuntimeError('could not find identifiers for ' + community)\n",
    "        \n",
    "    # set the destinations\n",
    "    es_fp = os.path.join(this_mock_dir, 'expected-sequences.fasta')\n",
    "    et_fp = os.path.join(this_mock_dir, 'matched-sequence-taxonomies.tsv')\n",
    "        \n",
    "    # check to see whether the expected sequences are precompiled ...\n",
    "    expected_expected = os.path.join(this_mockrobiota_dir, 'source', 'expected-sequences.fasta')\n",
    "    if os.path.exists(expected_expected):\n",
    "        print(community)\n",
    "        expected_sequences = skbio.io.read(expected_expected, format='fasta', constructor=skbio.DNA)\n",
    "        expected_ids = {' '.join([s.metadata['id'], s.metadata['description']]).strip() for s in expected_sequences}\n",
    "        shutil.copy(expected_expected, es_fp)\n",
    "        est_fp = os.path.join(this_mock_dir, 'expected-sequence-taxonomies.tsv')\n",
    "        with open(est_fp) as est_fh:\n",
    "            with open(et_fp, 'w') as et_fh:\n",
    "                reader = csv.reader(est_fh, delimiter='\\t')\n",
    "                writer = csv.writer(et_fh, delimiter='\\t')\n",
    "                writer.writerow(next(reader))\n",
    "                for tax_id, tax in reader:\n",
    "                    for exp_id in expected_ids:\n",
    "                        if community[5:] == '12':\n",
    "                            substring = ' '.join(exp_id.split(' ')[:2])\n",
    "                        elif community[5:] in ('3', '4', '5', '13', '14', '15'):\n",
    "                            _, substring, _ = exp_id.split('.')\n",
    "                        elif community[5:] == '16':\n",
    "                            substring = ' '.join(exp_id.split('_')[:2])\n",
    "                        if substring in tax_id:\n",
    "                            writer.writerow([exp_id, tax])\n",
    "            \n",
    "    # ... and otherwise derive the expected sequences from the identifiers and references\n",
    "    else:\n",
    "        identifier_file = os.path.join(identifier_file_dir, 'database-identifiers.tsv')\n",
    "        with open(identifier_file) as csvfile:\n",
    "            identifiers = csv.reader(csvfile, delimiter='\\t')\n",
    "            expected_sequences = []\n",
    "            for row in identifiers:\n",
    "                for _id in row[1].split():\n",
    "                    for seq in ref_seqs:\n",
    "                        if _id == seq.metadata['id']:\n",
    "                            expected_sequences.append(seq)\n",
    "                            break\n",
    "                    else:\n",
    "                        raise RuntimeError('could not find ' + _id + ' for ' + community)\n",
    "                        \n",
    "        # now write them out for safe-keeping\n",
    "        skbio.io.write((s for s in expected_sequences), 'fasta', es_fp)\n",
    "        print(community)\n",
    "        with open(et_fp, 'w') as et_fh:\n",
    "            writer = csv.writer(et_fh, delimiter='\\t')\n",
    "            writer.writerow(['Taxonomy', 'Standard Taxonomy'])\n",
    "            for seq in expected_sequences:\n",
    "                _id = seq.metadata['id']\n",
    "                writer.writerow([_id, taxonomy_map[_id]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map sequences that match to taxonomies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mock-1\n",
      "mock-10\n",
      "mock-12\n",
      "mock-13\n",
      "mock-14\n",
      "mock-15\n",
      "mock-16\n",
      "mock-2\n",
      "mock-3\n",
      "mock-4\n",
      "mock-5\n",
      "mock-6\n",
      "mock-7\n",
      "mock-8\n",
      "mock-9\n"
     ]
    }
   ],
   "source": [
    "for com_dir in glob.glob(os.path.join(expected_dir, '*')):\n",
    "    if not os.path.isdir(com_dir):\n",
    "        continue\n",
    "    community = os.path.basename(com_dir)\n",
    "    this_mock_dir = os.path.join(mock_dir, community)\n",
    "    \n",
    "    # load the taxonomy map\n",
    "    tax_file = os.path.join(this_mock_dir, 'matched-sequence-taxonomies.tsv')\n",
    "    with open(tax_file) as tf_fh:\n",
    "        reader = csv.reader(tf_fh, delimiter='\\t')\n",
    "        next(reader)\n",
    "        tax_map = {seq:tax for seq, tax in reader}\n",
    "    \n",
    "    # load the expected sequences\n",
    "    expected_file = os.path.join(this_mock_dir, 'expected-sequences.fasta')\n",
    "    expected_sequences = skbio.io.read(expected_file, format='fasta', constructor=skbio.DNA)\n",
    "                    \n",
    "    # compare with the observed sequences\n",
    "    observed_file = os.path.join(this_mock_dir, 'rep_seqs.fna')\n",
    "    observed = skbio.io.read(observed_file, format='fasta', constructor=skbio.DNA)\n",
    "    observed = list(observed)\n",
    "    mismatches = compare_observed_and_expected(observed, expected_sequences)\n",
    "    if len(mismatches) != len(observed):\n",
    "        print('warning: ', len(observed)-len(mismatches), 'out of', len(observed),\n",
    "              'observations not found for', community)\n",
    "        \n",
    "    # save the taxonomies of the matched reads\n",
    "    print(community)\n",
    "    max_mismatches = 3\n",
    "    result_file = os.path.join(this_mock_dir, 'trueish-taxonomies.tsv')\n",
    "    with open(result_file, 'w') as result_fh:\n",
    "        writer = csv.writer(result_fh, delimiter='\\t')\n",
    "        writer.writerow(['id', 'taxonomy'])\n",
    "        for rep_id, (mismatch, exp_id) in mismatches.items():\n",
    "            if mismatch <= max_mismatches:\n",
    "                if exp_id in tax_map:\n",
    "                    writer.writerow([rep_id, tax_map[exp_id]])\n",
    "                else:\n",
    "                    writer.writerow([rep_id, exp_id + ' not found'])\n",
    "            else:\n",
    "                writer.writerow([rep_id, 'other'])\n",
    "    \n",
    "    #feature_file = os.path.join(this_mock_dir, 'feature_table.qza')\n",
    "    #features = qiime2.Artifact.load(feature_file)\n",
    "    #features = features.view(pandas.DataFrame)\n",
    "    #best_mismatches = list(mismatches.values())\n",
    "    #weighted_mismatches = []\n",
    "    #for obs in mismatches:\n",
    "    #    try:\n",
    "    #        count = int(features[obs])\n",
    "    #    except TypeError:\n",
    "    #        count = int(sum(features[obs]))\n",
    "    #    weighted_mismatches.extend([mismatches[obs]]*count)\n",
    "    #print(community)\n",
    "    #sns.distplot(best_mismatches, kde=False, bins=50, axlabel='Number of Mismatches')\n",
    "    #matplotlib.pyplot.show()\n",
    "    #sns.distplot(weighted_mismatches, kde=False, bins=50, axlabel='Number of Mismatches')\n",
    "    #matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
