{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generation: using python to sweep over methods and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we illustrate how to use python to generate and run a list of commands. In this example, we generate a list of QIIME 1.9.0 ``assign_taxonomy.py`` commands, though this workflow for command generation is generally very useful for performing *parameter sweeps* (i.e., exploration of sets of parameters for achieving a specific result for comparative purposes). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os.path import join, expandvars \n",
    "from joblib import Parallel, delayed\n",
    "from glob import glob\n",
    "from tax_credit.framework_functions import (parameter_sweep,\n",
    "                                            generate_per_method_biom_tables,\n",
    "                                            move_results_to_repository)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project_dir = expandvars(\"$HOME/Desktop/projects/short-read-tax-assignment\")\n",
    "analysis_name= \"mock-community\"\n",
    "data_dir = join(project_dir, \"data\", analysis_name)\n",
    "\n",
    "reference_database_dir = expandvars(\"$HOME/Desktop/projects/short-read-tax-assignment/data/ref_dbs/\")\n",
    "results_dir = expandvars(\"$HOME/Desktop/projects/mock-community/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data set sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we're going to define the data sets that we'll sweep over. The following cell does not need to be modified unless if you wish to change the datasets or reference databases used in the sweep. Here we will use a single mock community, but two different versions of the reference database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_reference_combinations = [\n",
    " ('mock-3', 'gg_13_8_otus_trim150'),\n",
    " ('mock-3', 'gg_13_8_otus_full16S'),\n",
    " ('mock-9', 'unite_20.11.2016_trim100'),\n",
    " ('mock-9', 'unite_20.11.2016_fullITS'),\n",
    "]\n",
    "\n",
    "reference_dbs = {'gg_13_8_otus_trim150' : (join(reference_database_dir, 'gg_13_8_otus/99_otus_clean_515f-806r_trim150.fasta'), \n",
    "                                   join(reference_database_dir, 'gg_13_8_otus/99_otu_taxonomy_clean.tsv')),\n",
    "                 'gg_13_8_otus_full16S' : (join(reference_database_dir, 'gg_13_8_otus/99_otus_clean.fasta'), \n",
    "                                   join(reference_database_dir, 'gg_13_8_otus/99_otu_taxonomy_clean.tsv')),\n",
    "                 'unite_20.11.2016_trim100' : (join(reference_database_dir, 'unite_20.11.2016/sh_refs_qiime_ver7_99_20.11.2016_dev_clean_ITS1Ff-ITS2r_trim100.fasta'), \n",
    "                                   join(reference_database_dir, 'unite_20.11.2016/sh_taxonomy_qiime_ver7_99_20.11.2016_dev_clean.tsv')),\n",
    "                 'unite_20.11.2016_fullITS' : (join(reference_database_dir, 'unite_20.11.2016/sh_refs_qiime_ver7_99_20.11.2016_dev_clean.fasta'), \n",
    "                                   join(reference_database_dir, 'unite_20.11.2016/sh_taxonomy_qiime_ver7_99_20.11.2016_dev_clean.tsv'))\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the method/parameter combinations and generating commands\n",
    "\n",
    "Now we set the methods and method-specific parameters that we want to sweep. Modify to sweep other methods. Note how method_parameters_combinations feeds method/parameter combinations to parameter_sweep() in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Using QIIME 1 or Command-Line Classifiers\n",
    "\n",
    "Here we provide an example of taxonomy assignment using legacy ``QIIME 1`` classifiers executed on the command line. To accomplish this, we must first convert ``commands`` to a string, which we then pass to bash for execution. As ``QIIME 1`` is written in python-2, we must also activate a separate environment in which QIIME 1 [has been installed](http://qiime.org/install/install.html). If any environmental variables need to be set (in this example, the [RDP_JAR_PATH](http://qiime.org/install/alternative.html#rdp-jar-path-environment-variable)), we must also source the .bashrc file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "method_parameters_combinations = { # probabalistic classifiers\n",
    "              'rdp': {'confidence': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5,\n",
    "                                     0.6, 0.7, 0.8, 0.9, 1.0]},\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now enter the template of the command to sweep, and generate a list of commands with ``parameter_sweep()``.\n",
    "\n",
    "Fields must adhere to following format:\n",
    "\n",
    "                      {0} = output directory\n",
    "                      {1} = input data\n",
    "                      {2} = reference sequences\n",
    "                      {3} = reference taxonomy\n",
    "                      {4} = method name\n",
    "                      {5} = other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "command_template = \"mkdir -p {0} ; assign_taxonomy.py -v -i {1} -o {0} -r {2} -t {3} -m {4} {5} --rdp_max_memory 16000\"\n",
    "        \n",
    "commands = parameter_sweep(data_dir, results_dir, reference_dbs,\n",
    "                           dataset_reference_combinations,\n",
    "                           method_parameters_combinations, command_template,\n",
    "                           infile='rep_seqs.fna',)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, we can look at the first command that was generated and the number of commands generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mkdir -p /Users/nbokulich/Desktop/projects/mock-community/mock-9/unite_20.11.2016_trim100/rdp/0.0 ; assign_taxonomy.py -v -i /Users/nbokulich/Desktop/projects/short-read-tax-assignment/data/mock-community/mock-9/rep_seqs.fna -o /Users/nbokulich/Desktop/projects/mock-community/mock-9/unite_20.11.2016_trim100/rdp/0.0 -r /Users/nbokulich/Desktop/projects/short-read-tax-assignment/data/ref_dbs/unite_20.11.2016/sh_refs_qiime_ver7_99_20.11.2016_dev_clean_ITS1Ff-ITS2r_trim100.fasta -t /Users/nbokulich/Desktop/projects/short-read-tax-assignment/data/ref_dbs/unite_20.11.2016/sh_taxonomy_qiime_ver7_99_20.11.2016_dev_clean.tsv -m rdp --confidence 0.0 --rdp_max_memory 16000'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(commands))\n",
    "commands[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a simple subroutine function to run CLI commands in parallel. You will not need to modify the values in this cell unless if the conda environment in which qiime1 is installed has a different name, or if environmental parameters are not stored in .bashrc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_cli(command, env='qiime1'):\n",
    "    ! source activate qiime1; source ~/.bashrc; {command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we run our commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parallel(n_jobs=4)(delayed(run_cli)(command) for command in commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate per-method biom tables\n",
    "\n",
    "Modify the taxonomy_glob below to point to the taxonomy assignments that were generated above. This may be necessary if filepaths were altered in the preceding cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taxonomy_glob = join(results_dir, '*', '*', '*', '*', 'rep_seqs_tax_assignments.txt')\n",
    "generate_per_method_biom_tables(taxonomy_glob, data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move result files to repository\n",
    "\n",
    "Add results to the short-read-taxa-assignment directory (e.g., to push these results to the repository or compare with other precomputed results in downstream analysis steps). The precomputed_results_dir path and methods_dirs glob below should not need to be changed unless if substantial changes were made to filepaths in the preceding cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "precomputed_results_dir = join(project_dir, \"data\", \"precomputed-results\", analysis_name)\n",
    "for community in dataset_reference_combinations:\n",
    "    method_dirs = glob(join(results_dir, community[0], '*', '*', '*'))\n",
    "    move_results_to_repository(method_dirs, precomputed_results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Do not forget to copy the expected taxonomy files for this mock community!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for community in dataset_reference_combinations:\n",
    "    community_dir = join(precomputed_results_dir, community[0])\n",
    "    exp_observations = join(community_dir, '*', 'expected')\n",
    "    new_community_exp_dir = join(community_dir, community[1], 'expected')\n",
    "    !mkdir {new_community_exp_dir}; cp {exp_observations}/* {new_community_exp_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
