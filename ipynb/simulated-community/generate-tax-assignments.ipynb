{
 "metadata": {
  "name": "",
  "signature": "sha256:0c9185ecac8b5e0da8ce9630b1b64b3e7f6b615ad10a1f7cefc6ea2175e2cee2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Environment preparation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from os.path import join, exists, split, expandvars\n",
      "from os import makedirs\n",
      "from tempfile import mkstemp\n",
      "from glob import glob\n",
      "from itertools import product\n",
      "from random import shuffle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "project_dir = expandvars(\"$HOME/data/short-read-tax-assignment\")\n",
      "data_dir = join(project_dir, \"data\")\n",
      "\n",
      "reference_database_dir = expandvars(\"$HOME/data/\")\n",
      "results_dir = expandvars(\"$HOME/data/2015.02.25-tax-parameter-sweep-simulated\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Preparing data set sweep"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "rc = Client()\n",
      "lview = rc.load_balanced_view()\n",
      "\n",
      "@lview.parallel()\n",
      "def call_cmd(cmd):\n",
      "    from qcli import qcli_system_call\n",
      "    stdout, stderr, retval = qcli_system_call(cmd)\n",
      "    # return stdout, stderr, the return value, and the command\n",
      "    # the command is useful in case it needs to be re-run\n",
      "    return stdout, stderr, retval, cmd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, we're going to define the data sets that we'll sweep over."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_iterations = 5\n",
      "dataset_reference_combinations = []\n",
      "for iteration in range(num_iterations):\n",
      "    dataset_reference_combinations.append(('B1-iter%d' % iteration, 'gg_13_8_otus'))\n",
      "    dataset_reference_combinations.append(('B2-iter%d' % iteration, 'gg_13_8_otus'))\n",
      "    dataset_reference_combinations.append(('F1-iter%d' % iteration, 'unite-97-rep-set'))\n",
      "    dataset_reference_combinations.append(('F2-iter%d' % iteration, 'unite-97-rep-set'))\n",
      "\n",
      "reference_dbs = {'gg_13_8_otus' : (join(reference_database_dir, 'gg_13_8_otus/rep_set/97_otus.fasta'), \n",
      "                                   join(reference_database_dir, 'gg_13_8_otus/taxonomy/97_otu_taxonomy.txt')),\n",
      "                 'unite-97-rep-set' : (join(reference_database_dir, 'unite-14.11/97_otus.fasta'), \n",
      "                                       join(reference_database_dir, 'unite-14.11/97_otu_taxonomy.txt'))}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Uncompress simulated reference database files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "commands = []\n",
      "for e in dataset_reference_combinations:\n",
      "    zipped_refseqs_fp = join(data_dir, 'simulated-community', e[0], 'ref.fna.gz')\n",
      "    unzipped_refseqs_fp = join(data_dir, 'simulated-community', e[0], 'ref.fna')\n",
      "    cmd = \"gunzip -c %s > %s\" % (zipped_refseqs_fp, unzipped_refseqs_fp)\n",
      "    commands.append(cmd)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = call_cmd.map(commands)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Preparing the method/parameter combinations"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "method_parameters_combinations = { # probabalistic classifiers\n",
      "              'rdp': {'confidence': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
      "              \n",
      "              # global alignment classifiers\n",
      "              'uclust': {'min_consensus_fraction': [0.51, 0.76, 1.0], \n",
      "                         'similarity': [0.8, 0.9],\n",
      "                         'uclust_max_accepts': [1, 3, 5]},\n",
      "             \n",
      "              # local alignment classifiers\n",
      "              'sortmerna': {'sortmerna_e_value': [1.0],\n",
      "                            'min_consensus_fraction': [0.51, 0.76, 1.0], \n",
      "                            'similarity': [0.8, 0.9],\n",
      "                            'sortmerna_best_N_alignments ': [1, 3, 5],\n",
      "                            'sortmerna_coverage' : [0.8, 0.9]},\n",
      "              'blast': {'blast_e_value': [10000.0, 0.001, 0.000000001]}\n",
      "             }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "analyses = ['simulated-community']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "commands = []\n",
      "command_template = \"mkdir -p %s ; assign_taxonomy.py -i %s -o %s -r %s -t %s -m %s %s --rdp_max_memory 16000\"\n",
      "for analysis in analyses:\n",
      "    analysis_input_dir = join(data_dir, analysis)\n",
      "    analysis_output_dir = join(results_dir, analysis)\n",
      "    for dataset, reference in dataset_reference_combinations:\n",
      "        dataset_input_dir = join(analysis_input_dir, dataset)\n",
      "        dataset_input_seqs = join(dataset_input_dir, 'rep_set.fna')\n",
      "        dataset_input_table = join(dataset_input_dir, 'table.biom')\n",
      "        unzipped_reference_seqs = join(dataset_input_dir, 'ref.fna')\n",
      "        full_reference_seqs = reference_dbs[reference][0]\n",
      "        reference_tax = reference_dbs[reference][1]\n",
      "        dataset_output_dir = join(analysis_output_dir, dataset, reference)\n",
      "        for method, parameters in method_parameters_combinations.items():\n",
      "            method_output_dir = join(dataset_output_dir, method)\n",
      "            parameter_ids = parameters.keys()\n",
      "            parameter_ids.sort()\n",
      "            for parameter_combination in product(*[parameters[id_] for id_ in parameter_ids]):\n",
      "                parameter_comb_id = ':'.join(map(str,parameter_combination))\n",
      "                parameter_output_dir = join(method_output_dir, ''.join([parameter_comb_id, ':partial-ref']))\n",
      "                parameter_str = ' '.join(['--%s %s' % e for e in zip(parameter_ids, parameter_combination)])\n",
      "                command = command_template % (parameter_output_dir,\n",
      "                                              dataset_input_seqs, parameter_output_dir, unzipped_reference_seqs, \n",
      "                                              reference_tax, method, parameter_str)\n",
      "                if not exists(parameter_output_dir): commands.append(command)\n",
      "                full_output_dir = join(method_output_dir, ''.join([parameter_comb_id, ':full-ref']))\n",
      "                command = command_template % (parameter_output_dir,\n",
      "                                              dataset_input_seqs, full_output_dir, full_reference_seqs, \n",
      "                                              reference_tax, method, parameter_str)\n",
      "                if not exists(full_output_dir): commands.append(command)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shuffle(commands)\n",
      "print(len(commands))\n",
      "print commands[0]\n",
      "print commands[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "72\n",
        "mkdir -p /home/ubuntu/data/2015.02.25-tax-parameter-sweep-simulated/simulated-community/F1-iter0/unite-97-rep-set/sortmerna/0.76:0.8:5:0.9:1.0:partial-ref ; assign_taxonomy.py -i /home/ubuntu/data/short-read-tax-assignment/data/simulated-community/F1-iter0/rep_set.fna -o /home/ubuntu/data/2015.02.25-tax-parameter-sweep-simulated/simulated-community/F1-iter0/unite-97-rep-set/sortmerna/0.76:0.8:5:0.9:1.0:full-ref -r /home/ubuntu/data/unite-14.11/97_otus.fasta -t /home/ubuntu/data/unite-14.11/97_otu_taxonomy.txt -m sortmerna --min_consensus_fraction 0.76 --similarity 0.8 --sortmerna_best_N_alignments  5 --sortmerna_coverage 0.9 --sortmerna_e_value 1.0 --rdp_max_memory 16000\n",
        "mkdir -p /home/ubuntu/data/2015.02.25-tax-parameter-sweep-simulated/simulated-community/B1-iter1/gg_13_8_otus/uclust/0.51:0.9:1:partial-ref ; assign_taxonomy.py -i /home/ubuntu/data/short-read-tax-assignment/data/simulated-community/B1-iter1/rep_set.fna -o /home/ubuntu/data/2015.02.25-tax-parameter-sweep-simulated/simulated-community/B1-iter1/gg_13_8_otus/uclust/0.51:0.9:1:full-ref -r /home/ubuntu/data/gg_13_8_otus/rep_set/97_otus.fasta -t /home/ubuntu/data/gg_13_8_otus/taxonomy/97_otu_taxonomy.txt -m uclust --min_consensus_fraction 0.51 --similarity 0.9 --uclust_max_accepts 1 --rdp_max_memory 16000\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = call_cmd.map(commands)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(commands)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "2720"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Generate per-method biom tables"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "simulated_community_data_dir = join(short_read_tax_dir, 'data', 'simulated-community')\n",
      "biom_output_fps = []\n",
      "\n",
      "glob_str = join(results_dir, '*', '*', '*', '*', '*', '*', 'rep_set_tax_assignments.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for query_results_dir in query_results_dirs:\n",
      "    taxonomy_map_fps = glob(glob_str)\n",
      "    for taxonomy_map_fp in taxonomy_map_fps:\n",
      "        dataset_id = taxonomy_map_fp.split(sep)[-5]\n",
      "        biom_input_fp = join(simulated_community_data_dir, dataset_id, 'table-no-tax.biom')\n",
      "        output_dir = split(taxonomy_map_fp)[0]\n",
      "        biom_output_fp = join(output_dir,'table.biom')\n",
      "        !rm $biom_output_fp\n",
      "        cmd = \"biom add-metadata -i %s -o %s --observation-metadata-fp %s --observation-header otuid,taxonomy --sc-separated taxonomy --output-as-json\" % (biom_input_fp, biom_output_fp, taxonomy_map_fp)\n",
      "        !$cmd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Remove uncompressed reference databases"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "commands = []\n",
      "for e in dataset_reference_combinations:\n",
      "    unzipped_refseqs_fp = join(data_dir, 'simulated-community', e[0], 'ref.fna')\n",
      "    cmd = \"rm %s\" % unzipped_refseqs_fp\n",
      "    commands.append(cmd)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = call_cmd.map(commands)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Move result files into repository"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precomputed_results_dir = join(project_dir, \"data\", \"precomputed-results\", \"simulated-community\")\n",
      "method_dirs = glob(join(results_dir, '*', '*', '*', '*'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for method_dir in method_dirs:\n",
      "    fields = method_dir.split(sep)\n",
      "    dataset_id, database_id, method_id  = fields[-3], fields[-2], fields[-1] \n",
      "\n",
      "    new_location = join(precomputed_results_dir, dataset_id, database_id)\n",
      "    if exists(join(new_location, method_id)):\n",
      "        rmtree(join(new_location, method_id))\n",
      "    cmd = \"mv -f %s %s\" % (method_dir, new_location)\n",
      "    !$cmd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}