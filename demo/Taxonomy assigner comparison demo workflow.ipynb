{
 "metadata": {
  "name": "Taxonomy assigner comparison demo workflow"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Comparing taxonomy assigners: demo workflow"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This interactive notebook demonstrates what a workflow might look like when comparing two or more taxonomy assigners (or different assigner configurations, e.g. varying confidence levels). This example workflow is the basis for the comparisons that are made in the main text and supplementary materials of the paper. If you are interested in designing your own taxonomy assigner comparisons (e.g. comparing assigners not present in this study, trying out different datasets, etc.) this workflow is a good framework to start with."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Before you begin"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You'll need to have a working [QIIME](http://www.qiime.org) installation on the computer that this notebook will be running on. This notebook was tested with the latest development version of QIIME (at the time of writing), which is QIIME 1.7.0-dev, master@a94810a.\n",
      "\n",
      "You will also need a working installation of the [short-read-tax-assignment](https://github.com/gregcaporaso/short-read-tax-assignment) GitHub repository. Please see the README.md file included in that repository for installation details. This notebook was tested with commit ``` 1633d0b8f3007f5a82d5fac6ba1ea5054e390741``` of that repository."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Setting things up"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll download a sample dataset and choose a subset of sequences to work with, in order to reduce the time it takes to run the full demonstration. We'll also download the Greengenes 13_5 database, which we'll use as our reference database."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Download and extract the sample dataset.\n",
      "!wget ftp://thebeast.colorado.edu/pub/QIIME_DB_Public_Studies/study_1688_split_library_seqs_and_mapping.tgz\n",
      "!tar -zxf study_1688_split_library_seqs_and_mapping.tgz\n",
      "!gunzip study_1688_split_library_seqs_and_mapping/study_1688_split_library_seqs.fna.gz > study_1688_split_library_seqs_and_mapping/study_1688_split_library_seqs.fna\n",
      "\n",
      "# Subsample the dataset we just downloaded. Note: this will delete the original raw sequences file. Back it up if you care!\n",
      "!subsample_fasta.py -i study_1688_split_library_seqs_and_mapping/study_1688_split_library_seqs.fna -p 0.00005 -o study_1688_split_library_seqs_and_mapping/study_1688_split_library_seqs_subsampled.fna\n",
      "!mv study_1688_split_library_seqs_and_mapping/study_1688_split_library_seqs_subsampled.fna study_1688_split_library_seqs_and_mapping/study_1688_split_library_seqs.fna\n",
      "\n",
      "# Download and extract the Greengenes 13_5 database.\n",
      "!wget ftp://greengenes.microbio.me/greengenes_release/gg_13_5/gg_13_5_otus.tar.gz\n",
      "!tar -xzf gg_13_5_otus.tar.gz\n",
      "\n",
      "# Need to modify the reference database to remove spaces in the taxonomy strings, otherwise mothur will fail.\n",
      "!sed 's/; /;/g' gg_13_5_otus/taxonomy/97_otu_taxonomy.txt > gg_13_5_otus/taxonomy/97_otu_taxonomy_NO_SPACES.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll also set up some shortcuts to refer to common filepaths that will be used throughout the rest of the notebook."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "input_base = 'study_1688_split_library_seqs_and_mapping'\n",
      "input_seqs = join(input_base, 'study_1688_split_library_seqs.fna')\n",
      "\n",
      "otu_base = 'gg_13_5_otus'\n",
      "reference_seqs = join(otu_base, 'rep_set/97_otus.fasta')\n",
      "reference_tax = join(otu_base, 'taxonomy/97_otu_taxonomy_NO_SPACES.txt')\n",
      "\n",
      "otu_output_dir = join(input_base, 'otus')\n",
      "tax_output_dir = join(otu_output_dir, 'multiple_assign_taxonomy')\n",
      "\n",
      "# The known taxonomic composition of the mock community we're using in this workflow.\n",
      "mock_community_key = 'study_1688_split_library_seqs_and_mapping_key.txt'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "OTU picking"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we'll perform open-reference OTU picking on the demultiplexed sequences. The goal is to end up with a representative set of sequences that will be passed to the taxonomy assigners to have their taxonomy determined.\n",
      "\n",
      "Note that taxonomy assignment is suppressed during the OTU picking step because we want to have an OTU table without taxonomy. This table will have taxonomy assignments added to it for the various assigner/parameter combinations (see the next step in the workflow)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!pick_open_reference_otus.py --suppress_taxonomy_assignment -i $input_seqs -o $otu_output_dir -r $refence_seqs -p demo_params.txt -f"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Taxonomy assignment"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This next command performs multiple taxonomy assignments using BLAST, RDP, mothur, and RTAX. It uses various BLAST e-value thresholds and RDP/mothur confidence levels, and runs RTAX in single-end mode.\n",
      "\n",
      "Note that ```multiple_assign_taxonomy.py``` can operate on multiple input datasets. In this example, we are only specifying a single dataset in the interest of keeping the demo runtime relatively short."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!multiple_assign_taxonomy.py -m blast,rdp,mothur,rtax -e 100,0.0001,0.000001,1,1e-10,1e-30 -c 0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1 -r $reference_seqs -t $reference_tax --read_1_seqs_filename $input_seqs --rtax_amplicon_id_regexes '(\\S+)\\s(\\S+?)\\s' --rtax_header_id_regexes '\\S+\\s(\\S+?)\\s' -x single --clean_otu_table_filename otu_table_mc2_no_pynast_failures.biom -i $otu_output_dir -o $tax_output_dir -f"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Comparing results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!generate_taxa_compare_table.py -r $tax_output_dir -k $HOME/mock-community-compositions/ -o $HOME/study_1688_split_library_seqs_and_mapping/taxa_compare_table-13_5/ \n",
      "\n",
      "mkdir $HOME/study_1688_split_library_seqs_and_mapping/multiple_assign_taxonomy_13_5/psrotot_gg_13_5/Expected/\n",
      "cp $HOME/mock-community-compositions/S16S_key.txt $HOME/study_1688_split_library_seqs_and_mapping/multiple_assign_taxonomy_13_5/psrotot_gg_13_5/Expected/otu_table_mc2_w_taxa_L6.txt\n",
      "\n",
      "#make sure short-taxa-reads-bdiv-table.pl is in path\n",
      "perl short-taxa-reads-bdiv-table.pl $HOME/study_1688_split_library_seqs_and_mapping/multiple_assign_taxonomy_13_5/psrotot_gg_13_5/  \n",
      "\n",
      "convert_biom.py --biom_table_type=\"otu table\" --process_obs_metadata taxonomy -i $HOME/study_1688_split_library_seqs_and_mapping/multiple_assign_taxonomy_13_5/psrotot_gg_13_5/concatenated_otu_table.txt -o $HOME/study_1688_split_library_seqs_and_mapping/multiple_assign_taxonomy_13_5/psrotot_gg_13_5/concatenated_otu_table.biom\n",
      "\n",
      "beta_diversity_through_plots.py -m $HOME/study_1688_split_library_seqs_and_mapping/multiple_assign_taxonomy_13_5/psrotot_gg_13_5/concatenated_otu_map.txt -p $HOME/params/demo_params.txt --color_by_all_fields -f -i $HOME/study_1688_split_library_seqs_and_mapping/multiple_assign_taxonomy_13_5/psrotot_gg_13_5/concatenated_otu_table.biom -o $HOME/study_1688_split_library_seqs_and_mapping/concatenated_bdiv_plots/\n",
      "echo \"dbiv\"\n",
      "\n",
      "sed 's/^.*;//g' $HOME/study_1688_split_library_seqs_and_mapping/multiple_assign_taxonomy_13_5/psrotot_gg_13_5/concatenated_taxa_sum_L6.txt > $HOME/study_1688_split_library_seqs_and_mapping/multiple_assign_taxonomy_13_5/psrotot_gg_13_5/concatenated_taxa_sum_L6-genus-only.txt\n",
      "make_emperor.py --biplot_fp $HOME/study_1688_split_library_seqs_and_mapping/concatenated_bdiv_plots/bray_curtis_3d_discrete_taxa/taxa_coordinates.txt -b \"assignment_method,Description\" -m $HOME/study_1688_split_library_seqs_and_mapping/multiple_assign_taxonomy_13_5/psrotot_gg_13_5/concatenated_otu_map.txt -n -1 -i $HOME/study_1688_split_library_seqs_and_mapping/concatenated_bdiv_plots/bray_curtis_pc.txt -o $HOME/study_1688_split_library_seqs_and_mapping/concatenated_bdiv_plots/bray_curtis_3d_discrete_taxa/ -t $HOME/study_1688_split_library_seqs_and_mapping/multiple_assign_taxonomy_13_5/psrotot_gg_13_5/concatenated_taxa_sum_L6-genus-only.txt\n",
      "echo \"emperor\" \n",
      "\n",
      "make_bipartite_network.py --osizes 'Abundance' --ssizes 'Abundance' --scolors 'assignment_method' --ocolors 'p' --sshapes 'Description' --oshapes 'f,g' -k taxonomy --md_fields mock,k,p,c,o,f,g -m $HOME/study_1688_split_library_seqs_and_mapping/multiple_assign_taxonomy_13_5/psrotot_gg_13_5/concatenated_otu_map.txt -i $HOME/study_1688_split_library_seqs_and_mapping/multiple_assign_taxonomy_13_5/psrotot_gg_13_5/concatenated_otu_table.biom -o $HOME/study_1688_split_library_seqs_and_mapping/bipartite_network/\n",
      "echo \"network\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}